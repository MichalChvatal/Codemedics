{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375d0a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import iris\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from openai import OpenAI\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c150491c",
   "metadata": {},
   "source": [
    "### Connect to server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11fbff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conn = iris.connect(\"localhost\", 32782, \"DEMO\", \"_SYSTEM\", \"ISCDEMO\") # Server, Port , Namespace, Username, Password\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99536ff2",
   "metadata": {},
   "source": [
    "### Make database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4269a401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to InterSystems IRIS\n"
     ]
    }
   ],
   "source": [
    "print(\"Connected to InterSystems IRIS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "792a1157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create database\n",
    "df = pd.read_json(\"./data/data.json\") #pd.DataFrame(out, columns=cols)  #replace with Tristans/Iaroslavs code\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d783a",
   "metadata": {},
   "source": [
    "### Make encoding / add it to database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecf9ea11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7f9d8a16c8492fa1a04101cad55ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Make encoding \n",
    "#pip install sentence-transformers\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2') #might not work, if this is the case use instead 'all-MiniLM-L6-v2'\n",
    "\n",
    "\n",
    "def vectorize_content(df):\n",
    "    embeddings = model.encode(df['content'].tolist(), normalize_embeddings=True, show_progress_bar=True)\n",
    "    return embeddings\n",
    "\n",
    "def vectorize_filename(df):\n",
    "    embeddings = model.encode(df['filename'].tolist(), normalize_embeddings=True, show_progress_bar=True)\n",
    "    return embeddings\n",
    "\n",
    "embeddings = vectorize_content(df)\n",
    "df['vector'] = embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd0e3b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "###Add to Iris:\n",
    "def create_table(df):\n",
    "    table_name = \"VectorSearch.ORGstruct\"\n",
    "\n",
    "    create_table_query = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "    id INTEGER,\n",
    "    filename LONGVARCHAR,\n",
    "    content LONGVARCHAR,\n",
    "    vector VECTOR(DOUBLE, 384)\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "\n",
    "\n",
    "    insert_query = f\"INSERT INTO {table_name} (id, filename, content, vector) values (?, ?, ?, TO_VECTOR(?))\"\n",
    "    df[\"vector\"] = df[\"vector\"].astype(str)\n",
    "\n",
    "    rows_list = df[[\"id\", \"filename\", \"content\", \"vector\"]].values.tolist()\n",
    "    cursor.executemany(insert_query, rows_list)\n",
    "    print(\"Done\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "create_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66124774",
   "metadata": {},
   "source": [
    "### LLM setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec4158ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=\"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\"\n",
    ")\n",
    "OPENAI_API_KEY = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16bbcd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  api_key=\"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\"\n",
    ")\n",
    "\n",
    "\n",
    "class RAGChatbot:\n",
    "    def __init__(self):\n",
    "        self.message_count = 0\n",
    "        conn = iris.connect(\"localhost\", 32782, \"DEMO\", \"_SYSTEM\", \"ISCDEMO\") # Server, Port , Namespace, Username, Password\n",
    "        self.cursor = conn.cursor()\n",
    "        self.agent = self.create_agent()\n",
    "        self.embedding_model = self.get_embedding_model()\n",
    "        \n",
    "        \n",
    "    def get_embedding_model(self):\n",
    "        return  SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "    def create_agent(self):\n",
    "        # Initialize model\n",
    "        \n",
    "        # Initialise short-term memory\n",
    "        checkpointer = InMemorySaver()\n",
    "        \n",
    "        # Create model\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-5.1\",\n",
    "            temperature=0.1,\n",
    "            openai_api_key=OPENAI_API_KEY,\n",
    "        )\n",
    "\n",
    "        \n",
    "        agent = create_agent(\n",
    "            model=llm, \n",
    "            middleware=[\n",
    "                SummarizationMiddleware(\n",
    "                    model=llm,\n",
    "                    trigger=('tokens', 4000),  # Trigger summarization at 4000 tokens\n",
    "                    keep=('messages', 20),  # Keep last 20 messages after summary\n",
    "                )\n",
    "            ],\n",
    "            # Creates the agent's memory with pre-initialized model\n",
    "            checkpointer=checkpointer,\n",
    "        )\n",
    "        self.config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "        return agent\n",
    "        \n",
    "    def vector_search(self, user_prompt): \n",
    "        search_vector =  self.embedding_model.encode(user_prompt, normalize_embeddings=False, show_progress_bar=False).tolist() \n",
    "        \n",
    "        search_sql = f\"\"\"\n",
    "            SELECT TOP 5 filename, content \n",
    "            FROM VectorSearch.ORGstruct\n",
    "            ORDER BY VECTOR_COSINE(vector, TO_VECTOR(?,DOUBLE)) DESC\n",
    "        \"\"\"\n",
    "\n",
    "        self.cursor.execute(search_sql, [str(search_vector)])\n",
    "        \n",
    "\n",
    "        results = self.cursor.fetchall()\n",
    "\n",
    "        results = [f\"Text z dokumentu {x} -> {y}\" for x, y in results]\n",
    "\n",
    "\n",
    "        return results\n",
    "\n",
    "    def get_prompt(self):\n",
    "       \n",
    "        query = input(\"\\n\\nHi, I'm a chatbot used for searching a patient's medical history. How can I help you today? \\n\\n - User: \")\n",
    "    \n",
    "        return query\n",
    "    \n",
    "    def validation(self, result):\n",
    "\n",
    "        return result\n",
    "    \n",
    "\n",
    "    def return_response(self):\n",
    "        query = self.get_prompt()\n",
    "\n",
    "        search = True\n",
    "        if self.message_count != 0:\n",
    "            search_ans = input(\"Search the database? [Y/N - default N]\")\n",
    "            if search_ans.lower() != \"y\":\n",
    "                search = False\n",
    "\n",
    "\n",
    "        if search:\n",
    " \n",
    "            results = self.vector_search(query)\n",
    " \n",
    "            if results == []:\n",
    "                print(\"No results found, check patient ID\")\n",
    "                return\n",
    "\n",
    "            prompt = f\"CONTEXT:\\n{results}\\n\\nUSER QUESTION:\\n{query}\"\n",
    "        else:\n",
    "            prompt = f\"USER QUESTION:\\n{query}\"\n",
    "\n",
    "        ##print(prompt)\n",
    "        system_prompt = \"\"\"\n",
    "- Jsi užitečný asistent, chatbot fungující v nemocnici.\n",
    "- Tvým posláním je odpovídat na dotazy zaměstnanců týkající se jejich práce a provádět je organizační strukturou nemocnice a administrativními procesy.\n",
    "- Poskytuj odpovědi přesně podle interních dokumentů, které jsou dostupné prostřednictvím RAG (retrieved context).\n",
    "Tvůj způsob práce:\n",
    "    1. Odpovídej v jazyku, jakým mluví uživatel.\n",
    "    2. Ptej se uživatele na jeden konkrétní krok procesu. Nikdy nepřeskakuj více kroků najednou.\n",
    "    3. Vysvětluj pouze to, co uživatel potřebuje vědět pro aktuální krok.\n",
    "    4. Pokud je dotaz faktický, vždy nejprve vyhledej informace v dokumentech RAG.\n",
    "    5. Neodpovídej věci, které nejsou v podkladech, raději uveď, že nejsou uvedeny, nebo navrhni, kde se hledají.\n",
    "    6. Pokud uživatel neví, co má dělat, navrhni další krok.\n",
    "    7. Vyhýbej se nepodloženému nebo podlézavému lichocení\n",
    "    8. Zachovej profesionalitu a střízlivou upřímnost\n",
    "Co nesmíš dělat:\n",
    "    1. Nevymýšlej si pravidla, která nejsou ve zdrojových dokumentech.\n",
    "    2. Nevytvářej interní postupy, pokud nejsou výslovně uvedené.\n",
    "    3. Nehádej hodnoty (např. sazby stravného).\n",
    "Hlavní cíl:\n",
    "    1. Uživatel má být bezpečně a krok za krokem proveden procesem či postupem tak, aby splnil veškeré požadavky směrnic a nic nevynechal.\n",
    "\n",
    "- Když se uživatel dotazuje na nějaký proces v nemocnici (např. \\\"Chci si stěžovat na nedostatečnou dokumentaci k webové aplikaci vyvinuté v Centru Informatiky (CI)\\\"),\n",
    "  1. Odpovídej jasně a požádej uživatele o upřesnění, pokud nemůžeš přesně určit proces, který je pro uživatele relevantní (v tomto případě proces dokumentace ze strany oddělení nezdravotnických aplikací, které je součástí CI).\n",
    "  2. Pokud má uživatel podle předpisů více možností, jak dosáhnout svého cíle, popiš dostupné možnosti a zeptej se uživatele, kterou si chce vybrat.\n",
    "    - Pokud musí kontaktovat jiného zaměstnance, ale nemáš jeho kontaktní údaje, *jasně mu sděl, že je nemáš*.\n",
    "    - Pokud musí kontaktovat jiného zaměstnance a ty máš jeho kontaktní údaje, poskytni mu tyto informace (jméno, telefonní číslo, e-mail).\n",
    "  3. Při odpovídání *vždy* upřednostňuj organizační informace z dodaných dokumentů. Pokud tam informace není dostupná, *informuj o tom uživatele* a nic si nevymýšlej.\n",
    "  4. Pokud nemáš informace o uživatelově dotazu nebo o tom, jak by měl uživatel v daném procesu postupovat, ale *máš* informace o tom, kde může uživatel získat kvalifikovanou pomoc, doporuč mu osoby, které má kontaktovat, a poskytni kontaktní informace (V tomto případě by měl uživatel kontaktovat oddělení nezdravotnických aplikací).\n",
    "  5. Na konci své odpovědi *vždy* odkazuj k dokumentům (text \"Z dokumentu XYZ.docx\", před ->), ze kterých jsi čerpal informace. Vypiš je na konci odpovědi ve formátu: \"Dále se můžete obrátit na dokument XYZ\".\n",
    "  6. Pokud uživatel poprosí o pomoc s procesem, proveď ho tím několika kroky, které musí podniknout, aby dosáhl svého cíle.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        context_msg = \"\"\n",
    "        if results:\n",
    "            joined = \"\\n\".join(results)\n",
    "            context_msg = (\n",
    "                \"Následuje kontext z nemocničních dokumentů. \"\n",
    "                \"Při odpovědi se drž těchto informací a na konci odpovědi odkaž na příslušné dokumenty.\\n\\n\"\n",
    "                f\"{joined}\"\n",
    "            )\n",
    "\n",
    "\n",
    "        messages = [(\"system\", system_prompt)]\n",
    "        if context_msg:\n",
    "            messages.append((\"system\", context_msg))\n",
    "        messages.append((\"user\", query))\n",
    "\n",
    "        response = self.agent.invoke({\"messages\": messages}, self.config)\n",
    "\n",
    "        #response = self.agent.invoke({\"messages\" : [(\"system\", system_prompt), (\"user\", query), (\"system\", str(results))]}, self.config)\n",
    "        \n",
    "        self.message_count += 1\n",
    "        \n",
    "        validated_response = self.validation(response)\n",
    "\n",
    "        return validated_response[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747b7e70",
   "metadata": {},
   "source": [
    "### Interface with chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55cfe6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = RAGChatbot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fc9e220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Administrativní kroky při nástupu se mohou lišit podle pracoviště, ale z informací, které mám, nejde přesně určit, na jaké oddělení nastupujete (např. klinika, KRNM, jiný útvar). Potřeboval bych upřesnit:\n",
      "- Na jaké oddělení / kliniku nastupujete?\n",
      "- Jde o nástup do standardního pracovního poměru, nebo např. úvazek na konkrétní projekt / výzkum?\n",
      "\n",
      "Obecně ale platí, že:\n",
      "\n",
      "1. **Bezprostřední nadřízený (vrchní / staniční sestra, vedoucí oddělení)**\n",
      "   - Je první osoba, na kterou byste se měla obrátit.\n",
      "   - Zajistí:\n",
      "     - rozpis směn a přidělení na konkrétní pracoviště,\n",
      "     - seznámení s provozem oddělení,\n",
      "     - seznámení s pracovní náplní a odpovědnostmi (ty jsou formálně dány pracovní náplní a příslušnými zákony).\n",
      "\n",
      "2. **Personální oddělení (HR)**\n",
      "   - S nimi se zpravidla řeší:\n",
      "     - pracovní smlouva a její dodatky,\n",
      "     - doklady ke kvalifikaci (diplom, registrace, specializace),\n",
      "     - vstupní lékařská prohlídka (pokud ještě není hotová),\n",
      "     - zařazení do platové třídy dle kvalifikace.\n",
      "   - Nemám bohužel konkrétní kontakty na personální oddělení ve Vašem případě – ty by Vám měl dát Váš vedoucí pracovník nebo je najdete v interním adresáři nemocnice.\n",
      "\n",
      "3. **Vedoucí oddělení / primář (u lůžkových a odborných pracovišť)**\n",
      "   - Stanovuje organizaci práce na oddělení a odpovídá za to, že každý zaměstnanec má:\n",
      "     - jasně určené kompetence a činnosti v pracovní náplni,\n",
      "     - splněné zákonné kvalifikační požadavky (u sester dle zákonů č. 95/2004 Sb. a 96/2004 Sb., v případě některých pracovišť i dle zákona č. 263/2016 Sb. – atomový zákon, např. na nukleární medicíně).\n",
      "\n",
      "4. **Pokud nastupujete na specifické pracoviště (např. nukleární medicína, výzkum)**\n",
      "   - Na těchto pracovištích bývají:\n",
      "     - další vstupní školení (radiační ochrana, práce na výzkumných projektech),\n",
      "     - specifické interní předpisy.\n",
      "   - Operativní řízení (např. u vědy a výzkumu) vychází z aktuálních úkolů zadaných vedením a komunikace probíhá často elektronicky – nadřízený Vám sdělí, jaké výkazy, hlášení nebo úkoly budete plnit a v jaké formě.\n",
      "\n",
      "---\n",
      "\n",
      "Navrhuji postup:\n",
      "\n",
      "1. Napište/protože: **komu konkrétně nastupujete (oddělení/kliniky/pracoviště)** – podle toho Vám mohu poradit přesněji.  \n",
      "2. Jako první kontaktujte **svého přímého nadřízeného (vrchní/staniční sestru)** – požádejte ji o:\n",
      "   - seznam lidí, se kterými máte projít nástup (HR, BOZP, IT, školení),\n",
      "   - předání interních předpisů a Vaší pracovní náplně.\n",
      "3. Zeptejte se, zda je potřeba:\n",
      "   - absolvovat ještě nějaké specifické školení (např. radiační ochrana, pokud jste na pracovišti s ionizujícím zářením),\n",
      "   - doložit další dokumenty (specializovaná způsobilost, kurzy).\n",
      "\n",
      "Pokud mi doplníte, na jaké oddělení přesně nastupujete, popíšu Vám konkrétněji, koho a v jakém pořadí kontaktovat.\n",
      "\n",
      "Dále se můžete obrátit na dokument:\n",
      "- „Organizační řád – nukleární medicína“  \n",
      "- „Organizační řád – útvar pro vědu a výzkum“\n"
     ]
    }
   ],
   "source": [
    "bot.return_response()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
