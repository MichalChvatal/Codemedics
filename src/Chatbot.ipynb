{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "375d0a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import iris\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from openai import OpenAI\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c150491c",
   "metadata": {},
   "source": [
    "### Connect to server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11fbff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conn = iris.connect(\"localhost\", 32782, \"DEMO\", \"_SYSTEM\", \"ISCDEMO\") # Server, Port , Namespace, Username, Password\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99536ff2",
   "metadata": {},
   "source": [
    "### Make database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4269a401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to InterSystems IRIS\n"
     ]
    }
   ],
   "source": [
    "print(\"Connected to InterSystems IRIS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "792a1157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create database\n",
    "df = pd.read_json(\"./data/data.json\") #pd.DataFrame(out, columns=cols)  #replace with Tristans/Iaroslavs code\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d783a",
   "metadata": {},
   "source": [
    "### Make encoding / add it to database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecf9ea11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d79fbe7afb449b1974abb66bb0b330d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Make encoding \n",
    "#pip install sentence-transformers\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2') #might not work, if this is the case use instead 'all-MiniLM-L6-v2'\n",
    "\n",
    "\n",
    "def vectorize_content(df):\n",
    "    embeddings = model.encode(df['content'].tolist(), normalize_embeddings=True, show_progress_bar=True)\n",
    "    return embeddings\n",
    "\n",
    "def vectorize_filename(df):\n",
    "    embeddings = model.encode(df['filename'].tolist(), normalize_embeddings=True, show_progress_bar=True)\n",
    "    return embeddings\n",
    "\n",
    "embeddings = vectorize_content(df)\n",
    "df['vector'] = embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd0e3b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "###Add to Iris:\n",
    "def create_table(df):\n",
    "    table_name = \"VectorSearch.ORGstruct\"\n",
    "\n",
    "    create_table_query = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "    id INTEGER,\n",
    "    filename LONGVARCHAR,\n",
    "    content LONGVARCHAR,\n",
    "    vector VECTOR(DOUBLE, 384)\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "\n",
    "\n",
    "    insert_query = f\"INSERT INTO {table_name} (id, filename, content, vector) values (?, ?, ?, TO_VECTOR(?))\"\n",
    "    df[\"vector\"] = df[\"vector\"].astype(str)\n",
    "\n",
    "    rows_list = df[[\"id\", \"filename\", \"content\", \"vector\"]].values.tolist()\n",
    "    cursor.executemany(insert_query, rows_list)\n",
    "    print(\"Done\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "create_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66124774",
   "metadata": {},
   "source": [
    "### LLM setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec4158ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=\"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\"\n",
    ")\n",
    "OPENAI_API_KEY = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bbcd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  api_key=\"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\"\n",
    ")\n",
    "\n",
    "\n",
    "class RAGChatbot:\n",
    "    def __init__(self):\n",
    "        self.message_count = 0\n",
    "        conn = iris.connect(\"localhost\", 32782, \"DEMO\", \"_SYSTEM\", \"ISCDEMO\") # Server, Port , Namespace, Username, Password\n",
    "        self.cursor = conn.cursor()\n",
    "        self.agent = self.create_agent()\n",
    "        self.embedding_model = self.get_embedding_model()\n",
    "        \n",
    "        \n",
    "    def get_embedding_model(self):\n",
    "        return  SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "    def create_agent(self):\n",
    "        # Initialize model\n",
    "        \n",
    "        # Initialise short-term memory\n",
    "        checkpointer = InMemorySaver()\n",
    "        \n",
    "        # Create model\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-5.1\",\n",
    "            temperature=0.1,\n",
    "            openai_api_key=OPENAI_API_KEY,\n",
    "        )\n",
    "\n",
    "        \n",
    "        agent = create_agent(\n",
    "            model=llm, \n",
    "            middleware=[\n",
    "                SummarizationMiddleware(\n",
    "                    model=llm,\n",
    "                    trigger=('tokens', 4000),  # Trigger summarization at 4000 tokens\n",
    "                    keep=('messages', 20),  # Keep last 20 messages after summary\n",
    "                )\n",
    "            ],\n",
    "            # Creates the agent's memory with pre-initialized model\n",
    "            checkpointer=checkpointer,\n",
    "        )\n",
    "        self.config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "        return agent\n",
    "        \n",
    "    def vector_search(self, user_prompt): \n",
    "        search_vector =  self.embedding_model.encode(user_prompt, normalize_embeddings=False, show_progress_bar=False).tolist() \n",
    "        \n",
    "        search_sql = f\"\"\"\n",
    "            SELECT TOP 10 filename, content \n",
    "            FROM VectorSearch.ORGstruct\n",
    "            ORDER BY VECTOR_COSINE(vector, TO_VECTOR(?,DOUBLE)) DESC\n",
    "        \"\"\"\n",
    "\n",
    "        self.cursor.execute(search_sql, [str(search_vector)])\n",
    "        \n",
    "\n",
    "        results = self.cursor.fetchall()\n",
    "\n",
    "        results = [f\"Text z dokumentu {x} -> {y}\" for x, y in results]\n",
    "\n",
    "\n",
    "        return results\n",
    "\n",
    "    def get_prompt(self):\n",
    "       \n",
    "        query = input(\"\\n\\nHi, I'm a chatbot used for searching a patient's medical history. How can I help you today? \\n\\n - User: \")\n",
    "    \n",
    "        return query\n",
    "    \n",
    "    def validation(self, result):\n",
    "\n",
    "        return result\n",
    "    \n",
    "\n",
    "    def return_response(self):\n",
    "        query = self.get_prompt()\n",
    "        results = self.vector_search(query)\n",
    " \n",
    "        \n",
    "        ##print(prompt)\n",
    "        system_prompt = \"\"\"\n",
    "- Jsi užitečný asistent, chatbot fungující v nemocnici.\n",
    "- Tvým posláním je odpovídat na dotazy zaměstnanců týkající se jejich práce a provádět je organizační strukturou nemocnice a administrativními procesy.\n",
    "- Poskytuj odpovědi přesně podle interních dokumentů, které jsou dostupné prostřednictvím RAG (retrieved context).\n",
    "Tvůj způsob práce:\n",
    "    1. Odpovídej v jazyku, jakým mluví uživatel.\n",
    "    2. Ptej se uživatele na jeden konkrétní krok procesu. Nikdy nepřeskakuj více kroků najednou.\n",
    "    3. Vysvětluj pouze to, co uživatel potřebuje vědět pro aktuální krok.\n",
    "    4. Pokud je dotaz faktický, vždy nejprve vyhledej informace v dokumentech RAG.\n",
    "    5. Neodpovídej věci, které nejsou v podkladech, raději uveď, že nejsou uvedeny, nebo navrhni, kde se hledají.\n",
    "    6. Pokud uživatel neví, co má dělat, navrhni další krok.\n",
    "    7. Vyhýbej se nepodloženému nebo podlézavému lichocení\n",
    "    8. Zachovej profesionalitu a střízlivou upřímnost\n",
    "Co nesmíš dělat:\n",
    "    1. Nevymýšlej si pravidla, která nejsou ve zdrojových dokumentech.\n",
    "    2. Nevytvářej interní postupy, pokud nejsou výslovně uvedené.\n",
    "    3. Nehádej hodnoty (např. sazby stravného).\n",
    "Hlavní cíl:\n",
    "    1. Uživatel má být bezpečně a krok za krokem proveden procesem či postupem tak, aby splnil veškeré požadavky směrnic a nic nevynechal.\n",
    "\n",
    "- Když se uživatel dotazuje na nějaký proces v nemocnici (např. \\\"Chci si stěžovat na nedostatečnou dokumentaci k webové aplikaci vyvinuté v Centru Informatiky (CI)\\\"),\n",
    "  1. Odpovídej jasně a požádej uživatele o upřesnění, pokud nemůžeš přesně určit proces, který je pro uživatele relevantní (v tomto případě proces dokumentace ze strany oddělení nezdravotnických aplikací, které je součástí CI).\n",
    "  2. Pokud má uživatel podle předpisů více možností, jak dosáhnout svého cíle, popiš dostupné možnosti a zeptej se uživatele, kterou si chce vybrat.\n",
    "    - Pokud musí kontaktovat jiného zaměstnance, ale nemáš jeho kontaktní údaje, *jasně mu sděl, že je nemáš*.\n",
    "    - Pokud musí kontaktovat jiného zaměstnance a ty máš jeho kontaktní údaje, poskytni mu tyto informace (jméno, telefonní číslo, e-mail).\n",
    "  3. Při odpovídání *vždy* upřednostňuj organizační informace z dodaných dokumentů. Pokud tam informace není dostupná, *informuj o tom uživatele* a nic si nevymýšlej.\n",
    "  4. Pokud nemáš informace o uživatelově dotazu nebo o tom, jak by měl uživatel v daném procesu postupovat, ale *máš* informace o tom, kde může uživatel získat kvalifikovanou pomoc, doporuč mu osoby, které má kontaktovat, a poskytni kontaktní informace (V tomto případě by měl uživatel kontaktovat oddělení nezdravotnických aplikací).\n",
    "  5. Na konci své odpovědi odkazuj k dokumentům (text \"Z dokumentu XYZ.docx\", před ->), ze kterých jsi čerpal informace, pokud jsou relevantní. Vypiš je na konci odpovědi ve formátu: \"Dále se můžete obrátit na dokument XYZ\". \n",
    "  6. Pokud uživatel poprosí o pomoc s procesem, proveď ho tím několika kroky, které musí podniknout, aby dosáhl svého cíle.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        context_msg = \"\"\n",
    "        if results:\n",
    "            joined = \"\\n\".join(results)\n",
    "            context_msg = (\n",
    "                \"Následuje kontext z nemocničních dokumentů. \"\n",
    "                \"Při odpovědi se drž těchto informací a na konci odpovědi odkaž na příslušné dokumenty.\\n\\n\"\n",
    "                f\"{joined}\"\n",
    "            )\n",
    "\n",
    "\n",
    "        messages = [(\"system\", system_prompt)]\n",
    "        if context_msg:\n",
    "            messages.append((\"system\", context_msg))\n",
    "        messages.append((\"user\", query))\n",
    "\n",
    "        response = self.agent.invoke({\"messages\": messages}, self.config)\n",
    "\n",
    "        #response = self.agent.invoke({\"messages\" : [(\"system\", system_prompt), (\"user\", query), (\"system\", str(results))]}, self.config)\n",
    "        \n",
    "        self.message_count += 1\n",
    "        \n",
    "        validated_response = self.validation(response)\n",
    "\n",
    "        return validated_response[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747b7e70",
   "metadata": {},
   "source": [
    "### Interface with chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55cfe6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = RAGChatbot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4fc9e220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Z interních dokumentů bohužel nevyčtu konkrétní jména ani kontakty na vedoucí pracovníky radiologie ani na personální oddělení, takže ti je nemohu říct přesně.\n",
      "\n",
      "V tvé situaci je teď nejdůležitější jeden konkrétní krok:  \n",
      "zjistit, kdo tě má kam zařadit (tedy kdo je za tvůj nástup zodpovědný).\n",
      "\n",
      "Nejprve je potřeba obrátit se na centrální místo, které řeší personální záležitosti a zařazení:\n",
      "\n",
      "1. Kontaktuj personální / mzdové oddělení, nebo\n",
      "2. pokud toto číslo/e-mail nemáš, zavolej na ústřednu nemocnice a požádej o spojení na:\n",
      "   - personální oddělení, nebo  \n",
      "   - sekretariát katedry / kliniky radiologie (podle toho, jak se vaše pracoviště jmenuje).\n",
      "\n",
      "Krátce jim řekni něco ve smyslu:  \n",
      "„Nastupuji jako všeobecná sestra na radiologii, ještě neznám své konkrétní pracoviště ani vedoucího. Prosím o kontakt na osobu, která má na starosti moje zařazení / nástup.“\n",
      "\n",
      "Až získáš jméno nebo kontakt na konkrétní osobu (vedoucí sestra, vedoucí lékař, personální referent), napiš mi ho a projdeme další krok – co si s sebou na první jednání připravit a co si od nich vyžádat.\n",
      "\n",
      "Dále se můžete obrátit na dokument „Organizační … Kanceláře ředitele.docx“ (část „Personální zabezpečení KŘ“) a „Organizační … nukleární medicíny.docx“ (část „Zastupování vedoucích zaměstnanců“).\n"
     ]
    }
   ],
   "source": [
    "bot.return_response()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
